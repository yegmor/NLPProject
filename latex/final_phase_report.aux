\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand*\HyPL@Entry[1]{}
\HyPL@Entry{0<</S/D>>}
\@writefile{toc}{\contentsline {part}{I\hspace  {1em}Word2Vec}{6}{part.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Word2Vec vocabulary size}}{6}{table.1}\protected@file@percent }
\newlabel{w2v_vocab-size}{{1}{6}{Word2Vec vocabulary size}{table.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces t-SNE visualization for man}}{7}{figure.1}\protected@file@percent }
\newlabel{word2vec_depression_man}{{1}{7}{t-SNE visualization for man}{figure.1}{}}
\@writefile{toc}{\contentsline {part}{II\hspace  {1em}Tokenization}{8}{part.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Tokenizer outcome based on different vocabulary sizes}}{9}{table.2}\protected@file@percent }
\newlabel{token_vocab-size}{{2}{9}{Tokenizer outcome based on different vocabulary sizes}{table.2}{}}
\@writefile{toc}{\contentsline {part}{III\hspace  {1em}Parsing}{10}{part.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces conll format of 6th and 7th sentences}}{11}{figure.2}\protected@file@percent }
\newlabel{parsing_conll}{{2}{11}{conll format of 6th and 7th sentences}{figure.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Universal Dependencies for 10 sentences}}{12}{figure.3}\protected@file@percent }
\newlabel{parsing_examples_UDtree}{{3}{12}{Universal Dependencies for 10 sentences}{figure.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Outputs for the my\_test.conll}}{13}{figure.4}\protected@file@percent }
\newlabel{parsing_output}{{4}{13}{Outputs for the my\_test.conll}{figure.4}{}}
\@writefile{toc}{\contentsline {part}{IV\hspace  {1em}Language Model}{14}{part.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Examples for simple language model}}{14}{figure.5}\protected@file@percent }
\newlabel{normal-lm_examples}{{5}{14}{Examples for simple language model}{figure.5}{}}
\@writefile{toc}{\contentsline {part}{V\hspace  {1em}Fine-tuning}{15}{part.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Training bert classification language model}}{15}{figure.6}\protected@file@percent }
\newlabel{classification-lm_train}{{6}{15}{Training bert classification language model}{figure.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Evaluating bert classification language model}}{16}{figure.7}\protected@file@percent }
\newlabel{classification-lm_eval}{{7}{16}{Evaluating bert classification language model}{figure.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Examples for bert classification model}}{16}{figure.8}\protected@file@percent }
\newlabel{classification-lm_examples}{{8}{16}{Examples for bert classification model}{figure.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Examples for distilgpt2 language model}}{17}{figure.9}\protected@file@percent }
\newlabel{finetune-lm_examples.png}{{9}{17}{Examples for distilgpt2 language model}{figure.9}{}}
\bibcite{bib0}{1}
\bibcite{bib1}{2}
\bibcite{bib2}{3}
\bibcite{bib3}{4}
\bibcite{bib4}{5}
\bibcite{bib5}{6}
\bibcite{bib6}{7}
\bibcite{bib7}{8}
\bibcite{bib8}{9}
\bibcite{bib9}{10}
\bibcite{bib10}{11}
\bibcite{bib11}{12}
\bibcite{bib12}{13}
