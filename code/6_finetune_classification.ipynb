{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../assets/a_type_readme.gif\" style=\"float:right ; margin: 10px ; width:300px;\"> \n",
    "<h1><left>NLP Project</left></h1>\n",
    "<h4><left>Using Natural Language Processing to better understand Depression & Anxiety</left></h4>\n",
    "___\n",
    "\n",
    "## 3. Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'datasets'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-0c641e538582>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_metric\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;31m# !pip install pandas transformers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'datasets'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import core, array\n",
    "# assert np.__version__ == \"1.19.5\"\n",
    "\n",
    "import pandas as pd\n",
    "import dataframe_image as dfi\n",
    "from random import randint\n",
    "\n",
    "# import seaborn as sns\n",
    "# sns.set_style(\"darkgrid\")\n",
    "\n",
    "import torch\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from pickle import dump\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from time import time \n",
    "import logging \n",
    "import multiprocessing\n",
    "\n",
    "from datasets import load_metric\n",
    " \n",
    "# !pip install pandas transformers\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import random\n",
    "from torch.onnx import export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename=\"../logs/6_finetune_classification.log\",\n",
    "                    format='%(asctime)s > %(message)s',\n",
    "                    filemode='w',\n",
    "                    level=logging.INFO)\n",
    "\n",
    "def add_time(intput_str, start_time=0):\n",
    "    return \"{}: {} min\".format(input_str, round((time() - start_time) / 60, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = pd.read_csv('../data/data_for_model.csv', keep_default_na=False)\n",
    "print(model_data.info())\n",
    "model_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_column = \"selftext_clean\"\n",
    "labels = {1: \"anxiety\", 0: \"depression\"}\n",
    "labels_str2idx = {'depression': 0, 'anxiety': 1}\n",
    "# model_data[\"megatext_clean\"].to_csv(data_path, header=None, index=None, sep='\\t', mode='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_length = 128\n",
    "# max sequence length for each document/sentence sample\n",
    "max_length = 512\n",
    "EPOCHS = 10\n",
    "TRAIN_BATCH_SIZE = 8\n",
    "EVAL_BATCH_SIZE = 8\n",
    "\n",
    "logging.info(\"Setting parameters-> max_length={}, EPOCHS={}, TRAIN_BATCH_SIZE={}, EVAL_BATCH_SIZE={}, \".format(max_length, EPOCHS, TRAIN_BATCH_SIZE, EVAL_BATCH_SIZE))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare data and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text, val_text, train_labels, val_labels = train_test_split(\n",
    "    model_data[data_column].tolist(), \n",
    "    model_data[\"is_anxiety\"].tolist(), \n",
    "    test_size=.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"google/bert_uncased_L-4_H-512_A-8\"\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_name, do_lower_case=True)\n",
    "\n",
    "logging.info(\"tokenizer-> tokenize the dataset, truncate when passed `max_length`, and pad with 0's when less than `max_length`={}\".format(max_length))   \n",
    "train_encodings = tokenizer(train_text, truncation=True, padding=True, max_length=max_length)\n",
    "val_encodings = tokenizer(val_text, truncation=True, padding=True, max_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RedditDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "logging.info(\"convert tokenized data into a torch Dataset named: RedditDataset\")   \n",
    "train_dataset = RedditDataset(train_encodings, train_labels)\n",
    "val_dataset = RedditDataset(val_encodings, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/bert_uncased_L-4_H-512_A-8 were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-4_H-512_A-8 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"load the pretrain model name: {}\".format(model_name))   \n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=len(labels)).to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"setting TrainingArguments for training\")   \n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='../models/bert_classification_lm', # output directory\n",
    "    evaluation_strategy=\"epoch\",                   # Evaluation is done at the end of each epoch.\n",
    "    num_train_epochs=EPOCHS,                       # total number of training epochs\n",
    "    per_device_train_batch_size=TRAIN_BATCH_SIZE,  # batch size per device during training\n",
    "    per_device_eval_batch_size=EVAL_BATCH_SIZE,    # batch size for evaluation\n",
    "    warmup_steps=500,                              # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,                             # strength of weight decay\n",
    "    logging_dir ='../logs/bert_classification_lm', # directory for storing logs\n",
    "    logging_steps=200,                             # log & save weights each logging_steps\n",
    "    load_best_model_at_end=True,                   # load the best model when finished training (default metric is loss) \n",
    "    # but you can specify `metric_for_best_model` argument to change to accuracy or other metric\n",
    "    save_total_limit=1,                            # limit the total amount of checkpoints. Deletes the older checkpoints.    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='1930' max='1930' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1930/1930 03:10, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.446038</td>\n",
       "      <td>1.187500</td>\n",
       "      <td>325.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.606900</td>\n",
       "      <td>0.370412</td>\n",
       "      <td>1.188600</td>\n",
       "      <td>324.739000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.374500</td>\n",
       "      <td>0.347635</td>\n",
       "      <td>1.196000</td>\n",
       "      <td>322.729000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.294500</td>\n",
       "      <td>0.534144</td>\n",
       "      <td>1.199100</td>\n",
       "      <td>321.916000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.227300</td>\n",
       "      <td>0.571521</td>\n",
       "      <td>1.201800</td>\n",
       "      <td>321.177000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.121500</td>\n",
       "      <td>0.631738</td>\n",
       "      <td>1.205400</td>\n",
       "      <td>320.236000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.088700</td>\n",
       "      <td>0.716783</td>\n",
       "      <td>1.207600</td>\n",
       "      <td>319.642000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.062300</td>\n",
       "      <td>0.753405</td>\n",
       "      <td>1.210900</td>\n",
       "      <td>318.777000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.048100</td>\n",
       "      <td>0.778459</td>\n",
       "      <td>1.210700</td>\n",
       "      <td>318.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.041200</td>\n",
       "      <td>0.779626</td>\n",
       "      <td>1.211300</td>\n",
       "      <td>318.662000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1930, training_loss=0.1956141222326249, metrics={'train_runtime': 191.3326, 'train_samples_per_second': 10.087, 'total_flos': 1364356812472320, 'epoch': 10.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    ")\n",
    "\n",
    "logging.info(\"give the training_args, train_dataset, and val_dataset, and start training\")   \n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "def compute_metrics1(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "def compute_metrics2(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    # calculate accuracy using sklearn's function\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "      'accuracy': acc,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='49' max='49' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [49/49 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.779626190662384,\n",
       " 'eval_accuracy': 0.8730569948186528,\n",
       " 'eval_runtime': 1.2255,\n",
       " 'eval_samples_per_second': 314.975}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=val_dataset,            # evaluation dataset\n",
    "    compute_metrics=compute_metrics1\n",
    ")\n",
    "logging.info(\"give the training_args, train_dataset, and val_dataset, and do evaluation\")   \n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save & Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../models/bert_classification_lm/tokenizer_config.json',\n",
       " '../models/bert_classification_lm/special_tokens_map.json',\n",
       " '../models/bert_classification_lm/vocab.txt',\n",
       " '../models/bert_classification_lm/added_tokens.json')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"../models/bert_classification_lm\"\n",
    "model.save_pretrained(model_path)\n",
    "tokenizer.save_pretrained(model_path)\n",
    "\n",
    "logging.info(\"the complete model and tokenizer is saved at {}\".format(model_path))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"the complete model and tokenizer is loaded from {}\".format(model_path))  \n",
    "model = BertForSequenceClassification.from_pretrained(model_path, num_labels=len(labels)).to(\"cuda\")\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(text):\n",
    "    # prepare our text into tokenized sequence\n",
    "    inputs = tokenizer(text, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\").to(\"cuda\")\n",
    "    # perform inference to our model\n",
    "    outputs = model(**inputs)\n",
    "    # get output probabilities by doing softmax\n",
    "    probs = outputs[0].softmax(1)\n",
    "    # executing argmax function to get the candidate label\n",
    "#     return labels[probs.argmax().item()]\n",
    "    return probs.argmax().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seed_text</th>\n",
       "      <th>predicted</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tired tired fighting live care anything tired ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>know one perfect life bad like literally every...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17 ive always attracted woman think pocd destr...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>love sport play never coached never played spo...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           seed_text  predicted  actual\n",
       "0  tired tired fighting live care anything tired ...          0       0\n",
       "1  know one perfect life bad like literally every...          0       0\n",
       "2  17 ive always attracted woman think pocd destr...          1       1\n",
       "3  love sport play never coached never played spo...          1       1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_count = 2\n",
    "results = []\n",
    "\n",
    "logging.info(\"generating {} examples for each label\".format(exp_count))  \n",
    "\n",
    "for label_str, label_int in labels_str2idx.items():\n",
    "    data = model_data[model_data[\"is_anxiety\"] == label_int][data_column]\n",
    "    \n",
    "    for i in range(exp_count):\n",
    "        seed_text = data[randint(data.index[0], data.index[-1]+1)]\n",
    "        while seed_text == \"emptypost\":\n",
    "            seed_text = data[randint(data.index[0], data.index[-1]+1)]\n",
    "\n",
    "        generated = get_prediction(seed_text)\n",
    "        \n",
    "        model_results = {}\n",
    "        model_results[\"seed_text\"] = seed_text\n",
    "        model_results[\"predicted\"] = generated\n",
    "        model_results[\"actual\"] = label_int\n",
    "\n",
    "        results.append(model_results) \n",
    "        \n",
    "pd.set_option(\"display.max_colwidth\", 1000)\n",
    "results = pd.DataFrame(results)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfi.export(results, '../reports/images/classification-lm_examples.png')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "964d23c0451dcf6eb9653ab29bf1b69d4b9cf2f8bbce59b0642e3dd73cc18be8"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.2 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}