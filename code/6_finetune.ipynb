{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../assets/a_type_readme.gif\" style=\"float:right ; margin: 10px ; width:300px;\"> \n",
    "<h1><left>NLP Project</left></h1>\n",
    "<h4><left>Using Natural Language Processing to better understand Depression & Anxiety</left></h4>\n",
    "___\n",
    "\n",
    "## 3. Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\yegmo\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (1.1.5)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.7.0-py3-none-any.whl (2.5 MB)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\yegmo\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\yegmo\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pandas) (2020.4)\n",
      "Requirement already satisfied: numpy>=1.15.4 in c:\\users\\yegmo\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pandas) (1.19.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\yegmo\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\yegmo\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers) (20.4)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\yegmo\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers) (4.59.0)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\yegmo\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers) (5.3.1)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.3-cp38-cp38-win_amd64.whl (2.0 MB)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.0.12-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\yegmo\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers) (2.24.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\yegmo\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers) (2020.11.13)\n",
      "Collecting huggingface-hub==0.0.8\n",
      "  Downloading huggingface_hub-0.0.8-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\yegmo\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\yegmo\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->transformers) (1.25.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\yegmo\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\yegmo\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yegmo\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->transformers) (2020.6.20)\n",
      "Requirement already satisfied: joblib in c:\\users\\yegmo\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sacremoses->transformers) (0.17.0)\n",
      "Requirement already satisfied: click in c:\\users\\yegmo\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Installing collected packages: filelock, tokenizers, sacremoses, huggingface-hub, transformers\n",
      "Successfully installed filelock-3.0.12 huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.7.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import core, array\n",
    "assert np.__version__ == \"1.19.5\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "import torch\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from pickle import dump\n",
    "from nltk import word_tokenize\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from time import time \n",
    "\n",
    "import logging \n",
    "\n",
    "import multiprocessing\n",
    " \n",
    "!pip install pandas transformers\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "from torch.onnx import export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename=\"../finetune.log\",\n",
    "                    format='%(asctime)s %(message)s',\n",
    "                    filemode='w')\n",
    "logger = logging.getLogger()\n",
    "\n",
    "def print_time(intput_str, start_time=0):\n",
    "    print(\"{}: {} min\".format(input_str, round((time() - start_time) / 60, 2)))\n",
    "    \n",
    "# #Setting the threshold of logger to DEBUG\n",
    "# logger.setLevel(logging.DEBUG)\n",
    "  \n",
    "# #Test messages\n",
    "# logger.debug(\"Harmless debug Message\")\n",
    "# logger.info(\"Just an information\")\n",
    "# logger.warning(\"Its a Warning\")\n",
    "# logger.error(\"Did you try to divide by zero\")\n",
    "# logger.critical(\"Internet is down\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1930 entries, 0 to 1929\n",
      "Data columns (total 13 columns):\n",
      " #   Column                     Non-Null Count  Dtype \n",
      "---  ------                     --------------  ----- \n",
      " 0   title                      1930 non-null   object\n",
      " 1   selftext                   1930 non-null   object\n",
      " 2   author                     1930 non-null   object\n",
      " 3   score                      1930 non-null   int64 \n",
      " 4   num_comments               1930 non-null   int64 \n",
      " 5   is_anxiety                 1930 non-null   int64 \n",
      " 6   url                        1930 non-null   object\n",
      " 7   selftext_clean             1930 non-null   object\n",
      " 8   selftext_broken_sentences  1930 non-null   object\n",
      " 9   selftext_broken_words      1930 non-null   object\n",
      " 10  title_clean                1930 non-null   object\n",
      " 11  author_clean               1930 non-null   object\n",
      " 12  megatext_clean             1930 non-null   object\n",
      "dtypes: int64(3), object(10)\n",
      "memory usage: 196.1+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>author</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>is_anxiety</th>\n",
       "      <th>url</th>\n",
       "      <th>selftext_clean</th>\n",
       "      <th>selftext_broken_sentences</th>\n",
       "      <th>selftext_broken_words</th>\n",
       "      <th>title_clean</th>\n",
       "      <th>author_clean</th>\n",
       "      <th>megatext_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our most-broken and least-understood rules is ...</td>\n",
       "      <td>We understand that most people who reply immed...</td>\n",
       "      <td>SQLwitch</td>\n",
       "      <td>2319</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.reddit.com/r/depression/comments/d...</td>\n",
       "      <td>understand people reply immediately op invitat...</td>\n",
       "      <td>['we understand that most people who reply imm...</td>\n",
       "      <td>['understand', 'people', 'reply', 'immediately...</td>\n",
       "      <td>broken least understood rule helper may invite...</td>\n",
       "      <td>sql witch</td>\n",
       "      <td>sql witch understand people reply immediately ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Regular Check-In Post, with important reminder...</td>\n",
       "      <td>Welcome to /r/depression's check-in post - a p...</td>\n",
       "      <td>SQLwitch</td>\n",
       "      <td>312</td>\n",
       "      <td>1136</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.reddit.com/r/depression/comments/m...</td>\n",
       "      <td>welcome r depression check post place take mom...</td>\n",
       "      <td>[\"welcome to /r/depression's check-in post - a...</td>\n",
       "      <td>['welcome', 'r', 'depression', 'check', 'post'...</td>\n",
       "      <td>regular check post important reminder private ...</td>\n",
       "      <td>sql witch</td>\n",
       "      <td>sql witch welcome r depression check post plac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Low</td>\n",
       "      <td>I'm so low rn I can't even type anything coher...</td>\n",
       "      <td>RagingFlock89</td>\n",
       "      <td>263</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.reddit.com/r/depression/comments/n...</td>\n",
       "      <td>low rn even type anything coherent want expres...</td>\n",
       "      <td>[\"i'm so low rn i can't even type anything coh...</td>\n",
       "      <td>['low', 'rn', 'even', 'type', 'anything', 'coh...</td>\n",
       "      <td>low</td>\n",
       "      <td>raging flock 89</td>\n",
       "      <td>raging flock 89 low rn even type anything cohe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Our most-broken and least-understood rules is ...   \n",
       "1  Regular Check-In Post, with important reminder...   \n",
       "2                                                Low   \n",
       "\n",
       "                                            selftext         author  score  \\\n",
       "0  We understand that most people who reply immed...       SQLwitch   2319   \n",
       "1  Welcome to /r/depression's check-in post - a p...       SQLwitch    312   \n",
       "2  I'm so low rn I can't even type anything coher...  RagingFlock89    263   \n",
       "\n",
       "   num_comments  is_anxiety  \\\n",
       "0           175           0   \n",
       "1          1136           0   \n",
       "2            43           0   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.reddit.com/r/depression/comments/d...   \n",
       "1  https://www.reddit.com/r/depression/comments/m...   \n",
       "2  https://www.reddit.com/r/depression/comments/n...   \n",
       "\n",
       "                                      selftext_clean  \\\n",
       "0  understand people reply immediately op invitat...   \n",
       "1  welcome r depression check post place take mom...   \n",
       "2  low rn even type anything coherent want expres...   \n",
       "\n",
       "                           selftext_broken_sentences  \\\n",
       "0  ['we understand that most people who reply imm...   \n",
       "1  [\"welcome to /r/depression's check-in post - a...   \n",
       "2  [\"i'm so low rn i can't even type anything coh...   \n",
       "\n",
       "                               selftext_broken_words  \\\n",
       "0  ['understand', 'people', 'reply', 'immediately...   \n",
       "1  ['welcome', 'r', 'depression', 'check', 'post'...   \n",
       "2  ['low', 'rn', 'even', 'type', 'anything', 'coh...   \n",
       "\n",
       "                                         title_clean     author_clean  \\\n",
       "0  broken least understood rule helper may invite...        sql witch   \n",
       "1  regular check post important reminder private ...        sql witch   \n",
       "2                                                low  raging flock 89   \n",
       "\n",
       "                                      megatext_clean  \n",
       "0  sql witch understand people reply immediately ...  \n",
       "1  sql witch welcome r depression check post plac...  \n",
       "2  raging flock 89 low rn even type anything cohe...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data = pd.read_csv('../data/data_for_model.csv', keep_default_na=False)\n",
    "print(model_data.info())\n",
    "model_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_column = \"selftext_clean\"\n",
    "# model_data[data_column][0]\n",
    "# model_data[\"megatext_clean\"]\n",
    "# sents = [eval(sent) for sent in model_data[\"selftext_broken_words\"]]\n",
    "# dp = model_data[\"selftext_broken_words\"].tolist()[1]\n",
    "# literal_eval(dp)\n",
    "# model_data[\"megatext_clean\"].to_csv(data_path, header=None, index=None, sep='\\t', mode='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>author</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>is_anxiety</th>\n",
       "      <th>url</th>\n",
       "      <th>selftext_clean</th>\n",
       "      <th>selftext_broken_sentences</th>\n",
       "      <th>selftext_broken_words</th>\n",
       "      <th>title_clean</th>\n",
       "      <th>author_clean</th>\n",
       "      <th>megatext_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our most-broken and least-understood rules is ...</td>\n",
       "      <td>We understand that most people who reply immed...</td>\n",
       "      <td>SQLwitch</td>\n",
       "      <td>2319</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.reddit.com/r/depression/comments/d...</td>\n",
       "      <td>understand people reply immediately op invitat...</td>\n",
       "      <td>['we understand that most people who reply imm...</td>\n",
       "      <td>['understand', 'people', 'reply', 'immediately...</td>\n",
       "      <td>broken least understood rule helper may invite...</td>\n",
       "      <td>sql witch</td>\n",
       "      <td>sql witch understand people reply immediately ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Regular Check-In Post, with important reminder...</td>\n",
       "      <td>Welcome to /r/depression's check-in post - a p...</td>\n",
       "      <td>SQLwitch</td>\n",
       "      <td>312</td>\n",
       "      <td>1136</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.reddit.com/r/depression/comments/m...</td>\n",
       "      <td>welcome r depression check post place take mom...</td>\n",
       "      <td>[\"welcome to /r/depression's check-in post - a...</td>\n",
       "      <td>['welcome', 'r', 'depression', 'check', 'post'...</td>\n",
       "      <td>regular check post important reminder private ...</td>\n",
       "      <td>sql witch</td>\n",
       "      <td>sql witch welcome r depression check post plac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Low</td>\n",
       "      <td>I'm so low rn I can't even type anything coher...</td>\n",
       "      <td>RagingFlock89</td>\n",
       "      <td>263</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.reddit.com/r/depression/comments/n...</td>\n",
       "      <td>low rn even type anything coherent want expres...</td>\n",
       "      <td>[\"i'm so low rn i can't even type anything coh...</td>\n",
       "      <td>['low', 'rn', 'even', 'type', 'anything', 'coh...</td>\n",
       "      <td>low</td>\n",
       "      <td>raging flock 89</td>\n",
       "      <td>raging flock 89 low rn even type anything cohe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I’m always amazed at how much energy healthy p...</td>\n",
       "      <td>When I wake up after 8 hours of decent sleep I...</td>\n",
       "      <td>cezzzie</td>\n",
       "      <td>1281</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.reddit.com/r/depression/comments/n...</td>\n",
       "      <td>wake 8 hour decent sleep still exhausted day e...</td>\n",
       "      <td>['when i wake up after 8 hours of decent sleep...</td>\n",
       "      <td>['wake', '8', 'hour', 'decent', 'sleep', 'stil...</td>\n",
       "      <td>always amazed much energy healthy people</td>\n",
       "      <td>ce zzz ie</td>\n",
       "      <td>ce zzz ie wake 8 hour decent sleep still exhau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30 and never lived a day in my life</td>\n",
       "      <td>I guess i have always been depressed but never...</td>\n",
       "      <td>ApprehensiveYou2385</td>\n",
       "      <td>36</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.reddit.com/r/depression/comments/n...</td>\n",
       "      <td>guess always depressed never really thought mu...</td>\n",
       "      <td>['i guess i have always been depressed but nev...</td>\n",
       "      <td>['guess', 'always', 'depressed', 'never', 'rea...</td>\n",
       "      <td>30 never lived day life</td>\n",
       "      <td>apprehensive 2385</td>\n",
       "      <td>apprehensive 2385 guess always depressed never...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1925</th>\n",
       "      <td>Any tips on how not to panic during a midterm?</td>\n",
       "      <td>I have an Applied Statics midterm tomorrow. I ...</td>\n",
       "      <td>Anomalistic_Username</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.reddit.com/r/Anxiety/comments/n3p5...</td>\n",
       "      <td>applied static midterm tomorrow already failed...</td>\n",
       "      <td>['i have an applied statics midterm tomorrow.'...</td>\n",
       "      <td>['applied', 'static', 'midterm', 'tomorrow', '...</td>\n",
       "      <td>tip panic midterm</td>\n",
       "      <td>mali stic username</td>\n",
       "      <td>mali stic username applied static midterm tomo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1926</th>\n",
       "      <td>I find myself apologizing really often, checki...</td>\n",
       "      <td>I've recently decided to stop smoking weed (so...</td>\n",
       "      <td>zedhenson</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.reddit.com/r/Anxiety/comments/n3n1...</td>\n",
       "      <td>recently decided stop smoking weed socially th...</td>\n",
       "      <td>[\"i've recently decided to stop smoking weed (...</td>\n",
       "      <td>['recently', 'decided', 'stop', 'smoking', 'we...</td>\n",
       "      <td>find apologizing really often checking behavior</td>\n",
       "      <td>zed henson</td>\n",
       "      <td>zed henson recently decided stop smoking weed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1927</th>\n",
       "      <td>I typed out my anxiety attack and thought I sh...</td>\n",
       "      <td>I recently got into a little habit where when ...</td>\n",
       "      <td>Tree-Nui-Tee</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.reddit.com/r/Anxiety/comments/n3oz...</td>\n",
       "      <td>recently got little habit thing get overwhelmi...</td>\n",
       "      <td>['i recently got into a little habit where whe...</td>\n",
       "      <td>['recently', 'got', 'little', 'habit', 'thing'...</td>\n",
       "      <td>typed anxiety attack thought share</td>\n",
       "      <td>tree nui tee</td>\n",
       "      <td>tree nui tee recently got little habit thing g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1928</th>\n",
       "      <td>something happened that just triggered my anxi...</td>\n",
       "      <td>i need someone to vent to please</td>\n",
       "      <td>Capzfan5</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.reddit.com/r/Anxiety/comments/n3gc...</td>\n",
       "      <td>need someone vent please</td>\n",
       "      <td>['i need someone to vent to please']</td>\n",
       "      <td>['need', 'someone', 'vent', 'please']</td>\n",
       "      <td>something happened triggered anxiety really bad</td>\n",
       "      <td>cap z fan 5</td>\n",
       "      <td>cap z fan 5 need someone vent please something...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1929</th>\n",
       "      <td>Fear of Unknown Person</td>\n",
       "      <td>Everytime I go to my Grandma's old house (she'...</td>\n",
       "      <td>PanamaPhys_</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.reddit.com/r/Anxiety/comments/n3ot...</td>\n",
       "      <td>everytime go grandma old house still alive ass...</td>\n",
       "      <td>[\"everytime i go to my grandma's old house (sh...</td>\n",
       "      <td>['everytime', 'go', 'grandma', 'old', 'house',...</td>\n",
       "      <td>fear unknown person</td>\n",
       "      <td>panama ph</td>\n",
       "      <td>panama ph everytime go grandma old house still...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1930 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "0     Our most-broken and least-understood rules is ...   \n",
       "1     Regular Check-In Post, with important reminder...   \n",
       "2                                                   Low   \n",
       "3     I’m always amazed at how much energy healthy p...   \n",
       "4                   30 and never lived a day in my life   \n",
       "...                                                 ...   \n",
       "1925     Any tips on how not to panic during a midterm?   \n",
       "1926  I find myself apologizing really often, checki...   \n",
       "1927  I typed out my anxiety attack and thought I sh...   \n",
       "1928  something happened that just triggered my anxi...   \n",
       "1929                             Fear of Unknown Person   \n",
       "\n",
       "                                               selftext                author  \\\n",
       "0     We understand that most people who reply immed...              SQLwitch   \n",
       "1     Welcome to /r/depression's check-in post - a p...              SQLwitch   \n",
       "2     I'm so low rn I can't even type anything coher...         RagingFlock89   \n",
       "3     When I wake up after 8 hours of decent sleep I...               cezzzie   \n",
       "4     I guess i have always been depressed but never...   ApprehensiveYou2385   \n",
       "...                                                 ...                   ...   \n",
       "1925  I have an Applied Statics midterm tomorrow. I ...  Anomalistic_Username   \n",
       "1926  I've recently decided to stop smoking weed (so...             zedhenson   \n",
       "1927  I recently got into a little habit where when ...          Tree-Nui-Tee   \n",
       "1928                   i need someone to vent to please              Capzfan5   \n",
       "1929  Everytime I go to my Grandma's old house (she'...           PanamaPhys_   \n",
       "\n",
       "      score  num_comments  is_anxiety  \\\n",
       "0      2319           175           0   \n",
       "1       312          1136           0   \n",
       "2       263            43           0   \n",
       "3      1281           120           0   \n",
       "4        36             5           0   \n",
       "...     ...           ...         ...   \n",
       "1925      2             0           1   \n",
       "1926      3             1           1   \n",
       "1927      2             4           1   \n",
       "1928      8             5           1   \n",
       "1929      2             0           1   \n",
       "\n",
       "                                                    url  \\\n",
       "0     https://www.reddit.com/r/depression/comments/d...   \n",
       "1     https://www.reddit.com/r/depression/comments/m...   \n",
       "2     https://www.reddit.com/r/depression/comments/n...   \n",
       "3     https://www.reddit.com/r/depression/comments/n...   \n",
       "4     https://www.reddit.com/r/depression/comments/n...   \n",
       "...                                                 ...   \n",
       "1925  https://www.reddit.com/r/Anxiety/comments/n3p5...   \n",
       "1926  https://www.reddit.com/r/Anxiety/comments/n3n1...   \n",
       "1927  https://www.reddit.com/r/Anxiety/comments/n3oz...   \n",
       "1928  https://www.reddit.com/r/Anxiety/comments/n3gc...   \n",
       "1929  https://www.reddit.com/r/Anxiety/comments/n3ot...   \n",
       "\n",
       "                                         selftext_clean  \\\n",
       "0     understand people reply immediately op invitat...   \n",
       "1     welcome r depression check post place take mom...   \n",
       "2     low rn even type anything coherent want expres...   \n",
       "3     wake 8 hour decent sleep still exhausted day e...   \n",
       "4     guess always depressed never really thought mu...   \n",
       "...                                                 ...   \n",
       "1925  applied static midterm tomorrow already failed...   \n",
       "1926  recently decided stop smoking weed socially th...   \n",
       "1927  recently got little habit thing get overwhelmi...   \n",
       "1928                           need someone vent please   \n",
       "1929  everytime go grandma old house still alive ass...   \n",
       "\n",
       "                              selftext_broken_sentences  \\\n",
       "0     ['we understand that most people who reply imm...   \n",
       "1     [\"welcome to /r/depression's check-in post - a...   \n",
       "2     [\"i'm so low rn i can't even type anything coh...   \n",
       "3     ['when i wake up after 8 hours of decent sleep...   \n",
       "4     ['i guess i have always been depressed but nev...   \n",
       "...                                                 ...   \n",
       "1925  ['i have an applied statics midterm tomorrow.'...   \n",
       "1926  [\"i've recently decided to stop smoking weed (...   \n",
       "1927  ['i recently got into a little habit where whe...   \n",
       "1928               ['i need someone to vent to please']   \n",
       "1929  [\"everytime i go to my grandma's old house (sh...   \n",
       "\n",
       "                                  selftext_broken_words  \\\n",
       "0     ['understand', 'people', 'reply', 'immediately...   \n",
       "1     ['welcome', 'r', 'depression', 'check', 'post'...   \n",
       "2     ['low', 'rn', 'even', 'type', 'anything', 'coh...   \n",
       "3     ['wake', '8', 'hour', 'decent', 'sleep', 'stil...   \n",
       "4     ['guess', 'always', 'depressed', 'never', 'rea...   \n",
       "...                                                 ...   \n",
       "1925  ['applied', 'static', 'midterm', 'tomorrow', '...   \n",
       "1926  ['recently', 'decided', 'stop', 'smoking', 'we...   \n",
       "1927  ['recently', 'got', 'little', 'habit', 'thing'...   \n",
       "1928              ['need', 'someone', 'vent', 'please']   \n",
       "1929  ['everytime', 'go', 'grandma', 'old', 'house',...   \n",
       "\n",
       "                                            title_clean        author_clean  \\\n",
       "0     broken least understood rule helper may invite...           sql witch   \n",
       "1     regular check post important reminder private ...           sql witch   \n",
       "2                                                   low     raging flock 89   \n",
       "3              always amazed much energy healthy people           ce zzz ie   \n",
       "4                               30 never lived day life   apprehensive 2385   \n",
       "...                                                 ...                 ...   \n",
       "1925                                  tip panic midterm  mali stic username   \n",
       "1926    find apologizing really often checking behavior          zed henson   \n",
       "1927                 typed anxiety attack thought share        tree nui tee   \n",
       "1928    something happened triggered anxiety really bad         cap z fan 5   \n",
       "1929                                fear unknown person           panama ph   \n",
       "\n",
       "                                         megatext_clean  \n",
       "0     sql witch understand people reply immediately ...  \n",
       "1     sql witch welcome r depression check post plac...  \n",
       "2     raging flock 89 low rn even type anything cohe...  \n",
       "3     ce zzz ie wake 8 hour decent sleep still exhau...  \n",
       "4     apprehensive 2385 guess always depressed never...  \n",
       "...                                                 ...  \n",
       "1925  mali stic username applied static midterm tomo...  \n",
       "1926  zed henson recently decided stop smoking weed ...  \n",
       "1927  tree nui tee recently got little habit thing g...  \n",
       "1928  cap z fan 5 need someone vent please something...  \n",
       "1929  panama ph everytime go grandma old house still...  \n",
       "\n",
       "[1930 rows x 13 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_queries, val_queries, train_docs, val_docs, train_labels, val_labels = train_test_split(\n",
    "    training_data[\"query\"].tolist(), \n",
    "    training_data[\"title\"].tolist(), \n",
    "    training_data[\"label\"].tolist(), \n",
    "    test_size=.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"google/bert_uncased_L-4_H-512_A-8\"\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
    "\n",
    "train_encodings = tokenizer(train_queries, train_docs, truncation=True, padding='max_length', max_length=128)\n",
    "val_encodings = tokenizer(val_queries, val_docs, truncation=True, padding='max_length', max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cord19Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = Cord19Dataset(train_encodings, train_labels)\n",
    "val_dataset = Cord19Dataset(val_encodings, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    evaluation_strategy=\"epoch\",     # Evaluation is done at the end of each epoch.\n",
    "    num_train_epochs=3,              # total number of training epochs\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    save_total_limit=1,              # limit the total amount of checkpoints. Deletes the older checkpoints.    \n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=val_dataset             # evaluation dataset\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") \n",
    "\n",
    "model_onnx_path = \"model.onnx\"\n",
    "dummy_input = (\n",
    "    train_dataset[0][\"input_ids\"].unsqueeze(0).to(device), \n",
    "    train_dataset[0][\"token_type_ids\"].unsqueeze(0).to(device), \n",
    "    train_dataset[0][\"attention_mask\"].unsqueeze(0).to(device)\n",
    ")\n",
    "input_names = [\"input_ids\", \"token_type_ids\", \"attention_mask\"]\n",
    "output_names = [\"logits\"]\n",
    "export(\n",
    "    model, dummy_input, model_onnx_path, input_names = input_names, \n",
    "    output_names = output_names, verbose=False, opset_version=11\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "964d23c0451dcf6eb9653ab29bf1b69d4b9cf2f8bbce59b0642e3dd73cc18be8"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
