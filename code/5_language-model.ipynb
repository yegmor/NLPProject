{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../assets/a_type_readme.gif\" style=\"float:right ; margin: 10px ; width:300px;\"> \n",
    "<h1><left>NLP Project</left></h1>\n",
    "<h4><left>Using Natural Language Processing to better understand Depression & Anxiety</left></h4>\n",
    "___\n",
    "\n",
    "## 3. Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\yegmo\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import core, array\n",
    "assert np.__version__ == \"1.19.5\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "import sentencepiece as spm\n",
    "\n",
    "import gensim\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "# from gensim.models import Word2Vec\n",
    "assert gensim.__version__ == \"4.0.1\"\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "\n",
    "import dataframe_image as dfi\n",
    "\n",
    "from pickle import dump, load\n",
    "\n",
    "from nltk import word_tokenize\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from time import time \n",
    "from random import randint\n",
    "import logging \n",
    "import multiprocessing\n",
    " \n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, LSTM, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename=\"../logs/5_language-model.log\",\n",
    "                    format='%(asctime)s > %(message)s',\n",
    "                    filemode='w',\n",
    "                    level=logging.INFO)\n",
    "\n",
    "def add_time(intput_str, start_time=0):\n",
    "    return \"{}: {} min\".format(input_str, round((time() - start_time) / 60, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1930 entries, 0 to 1929\nData columns (total 13 columns):\n #   Column                     Non-Null Count  Dtype \n---  ------                     --------------  ----- \n 0   title                      1930 non-null   object\n 1   selftext                   1930 non-null   object\n 2   author                     1930 non-null   object\n 3   score                      1930 non-null   int64 \n 4   num_comments               1930 non-null   int64 \n 5   is_anxiety                 1930 non-null   int64 \n 6   url                        1930 non-null   object\n 7   selftext_clean             1930 non-null   object\n 8   selftext_broken_sentences  1930 non-null   object\n 9   selftext_broken_words      1930 non-null   object\n 10  title_clean                1930 non-null   object\n 11  author_clean               1930 non-null   object\n 12  megatext_clean             1930 non-null   object\ndtypes: int64(3), object(10)\nmemory usage: 196.1+ KB\nNone\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                               title  \\\n",
       "0  Our most-broken and least-understood rules is ...   \n",
       "1  Regular Check-In Post, with important reminder...   \n",
       "2                                                Low   \n",
       "\n",
       "                                            selftext         author  score  \\\n",
       "0  We understand that most people who reply immed...       SQLwitch   2319   \n",
       "1  Welcome to /r/depression's check-in post - a p...       SQLwitch    312   \n",
       "2  I'm so low rn I can't even type anything coher...  RagingFlock89    263   \n",
       "\n",
       "   num_comments  is_anxiety  \\\n",
       "0           175           0   \n",
       "1          1136           0   \n",
       "2            43           0   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.reddit.com/r/depression/comments/d...   \n",
       "1  https://www.reddit.com/r/depression/comments/m...   \n",
       "2  https://www.reddit.com/r/depression/comments/n...   \n",
       "\n",
       "                                      selftext_clean  \\\n",
       "0  understand people reply immediately op invitat...   \n",
       "1  welcome r depression check post place take mom...   \n",
       "2  low rn even type anything coherent want expres...   \n",
       "\n",
       "                           selftext_broken_sentences  \\\n",
       "0  ['we understand that most people who reply imm...   \n",
       "1  [\"welcome to /r/depression's check-in post - a...   \n",
       "2  [\"i'm so low rn i can't even type anything coh...   \n",
       "\n",
       "                               selftext_broken_words  \\\n",
       "0  ['understand', 'people', 'reply', 'immediately...   \n",
       "1  ['welcome', 'r', 'depression', 'check', 'post'...   \n",
       "2  ['low', 'rn', 'even', 'type', 'anything', 'coh...   \n",
       "\n",
       "                                         title_clean     author_clean  \\\n",
       "0  broken least understood rule helper may invite...        sql witch   \n",
       "1  regular check post important reminder private ...        sql witch   \n",
       "2                                                low  raging flock 89   \n",
       "\n",
       "                                      megatext_clean  \n",
       "0  sql witch understand people reply immediately ...  \n",
       "1  sql witch welcome r depression check post plac...  \n",
       "2  raging flock 89 low rn even type anything cohe...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>selftext</th>\n      <th>author</th>\n      <th>score</th>\n      <th>num_comments</th>\n      <th>is_anxiety</th>\n      <th>url</th>\n      <th>selftext_clean</th>\n      <th>selftext_broken_sentences</th>\n      <th>selftext_broken_words</th>\n      <th>title_clean</th>\n      <th>author_clean</th>\n      <th>megatext_clean</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Our most-broken and least-understood rules is ...</td>\n      <td>We understand that most people who reply immed...</td>\n      <td>SQLwitch</td>\n      <td>2319</td>\n      <td>175</td>\n      <td>0</td>\n      <td>https://www.reddit.com/r/depression/comments/d...</td>\n      <td>understand people reply immediately op invitat...</td>\n      <td>['we understand that most people who reply imm...</td>\n      <td>['understand', 'people', 'reply', 'immediately...</td>\n      <td>broken least understood rule helper may invite...</td>\n      <td>sql witch</td>\n      <td>sql witch understand people reply immediately ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Regular Check-In Post, with important reminder...</td>\n      <td>Welcome to /r/depression's check-in post - a p...</td>\n      <td>SQLwitch</td>\n      <td>312</td>\n      <td>1136</td>\n      <td>0</td>\n      <td>https://www.reddit.com/r/depression/comments/m...</td>\n      <td>welcome r depression check post place take mom...</td>\n      <td>[\"welcome to /r/depression's check-in post - a...</td>\n      <td>['welcome', 'r', 'depression', 'check', 'post'...</td>\n      <td>regular check post important reminder private ...</td>\n      <td>sql witch</td>\n      <td>sql witch welcome r depression check post plac...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Low</td>\n      <td>I'm so low rn I can't even type anything coher...</td>\n      <td>RagingFlock89</td>\n      <td>263</td>\n      <td>43</td>\n      <td>0</td>\n      <td>https://www.reddit.com/r/depression/comments/n...</td>\n      <td>low rn even type anything coherent want expres...</td>\n      <td>[\"i'm so low rn i can't even type anything coh...</td>\n      <td>['low', 'rn', 'even', 'type', 'anything', 'coh...</td>\n      <td>low</td>\n      <td>raging flock 89</td>\n      <td>raging flock 89 low rn even type anything cohe...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "model_data = pd.read_csv('../data/data_for_model.csv', keep_default_na=False)\n",
    "print(model_data.info())\n",
    "data_column = \"selftext_clean\"\n",
    "model_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def organize_token_seqs(data, length=20+1):\n",
    "    logging.info(\"In organize_token_seqs-> sequence length={}\".format(length))    \n",
    "\n",
    "    sequences = list()\n",
    "    \n",
    "    for record in data:\n",
    "        tokens = word_tokenize(record)\n",
    "        \n",
    "        for i in range(length, len(tokens)):\n",
    "            seq = tokens[i-length: i]\n",
    "            assert len(seq) == length, (length, len(seq), seq)\n",
    "            line = ' '.join(seq)\n",
    "            sequences.append(line)\n",
    "        \n",
    "#     if len(sequences)== 0:\n",
    "#         print(tokens)\n",
    "#     print('Total Sequences: %d' % len(sequences))\n",
    "    \n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_doc(lines, filename):\n",
    "    logging.info(\"In save_doc-> filename={}\".format(filename))    \n",
    "    data = '\\n'.join(lines)\n",
    "    file = open(filename, 'w')\n",
    "    file.write(data)\n",
    "    file.close()\n",
    "    logging.info(\"In save_doc-> file save at {}\".format(filename))    \n",
    "    \n",
    "    \n",
    "def load_doc(filename):\n",
    "    logging.info(\"In load_doc-> filename={}\".format(filename))    \n",
    "    file = open(filename, 'r')\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    logging.info(\"In load_doc-> file loaded from {}\".format(filename))    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_LM_A(vocab_size, seq_length, summary=False):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, 50, input_length=seq_length))\n",
    "    model.add(LSTM(100, return_sequences=True))\n",
    "    model.add(LSTM(100))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(vocab_size, activation='softmax'))\n",
    "    \n",
    "    logging.info(\"In build_LM_A-> model summary\\n\", model.summary())\n",
    "    if summary:\n",
    "        print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def language_model(label, data, n_seq_words, model_path, tokenizer_path, processed_data_path, EPOCHS=100, BATCH=128, summary=False):\n",
    "    logging.info(\"In language_model-> label={}, n_seq_words={}, model_path={}, tokenizer_path={}, processed_data_path={}\".format(label, n_seq_words, model_path, tokenizer_path, processed_data_path))\n",
    "     \n",
    "    # ------------------------------ PREPARE DATA -----------------------------------\n",
    "    processed_data = organize_token_seqs(data, n_seq_words)\n",
    "    save_doc(processed_data, processed_data_path)\n",
    "\n",
    "#     doc = load_doc(processed_data_path)\n",
    "#     processed_data = doc.split('\\n')\n",
    "#     print(\"\\nword sequences\\n\", processed_data[:5])\n",
    "    \n",
    "    # integer encode sequences of words\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(processed_data)\n",
    "    unchecked_sequences = tokenizer.texts_to_sequences(processed_data)\n",
    "    \n",
    "    msg = \"BEFORE len(Sequences): {}\\n sequences lengths={}\".format(len(unchecked_sequences), set([len(seq) for seq in unchecked_sequences]))\n",
    "    logging.info(msg)\n",
    "    print(\"\\n\" +msg)\n",
    "    \n",
    "    sequences = []\n",
    "    for seq in unchecked_sequences:\n",
    "        if len(seq) == n_seq_words:\n",
    "            sequences.append(seq)\n",
    "    msg = 'AFTER len(Sequences): {}\\n sequences lengths={}'.format(len(sequences), set([len(seq) for seq in sequences]))\n",
    "    logging.info(msg)\n",
    "    print(\"\\n\" +msg)    \n",
    "\n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "    msg = 'tokenizer vocab_size={}'.format(vocab_size)\n",
    "    logging.info(msg)\n",
    "    print(\"\\n\" + msg)    \n",
    "    \n",
    "    # separate into input and output\n",
    "    sequences = array(sequences)\n",
    "    msg = 'sequences.shape={}'.format(sequences.shape)\n",
    "    logging.info(msg)\n",
    "    print(\"\\n\" + msg)\n",
    "    \n",
    "    X, y = sequences[:, :-1], sequences[:, -1]\n",
    "    \n",
    "    y = to_categorical(y, num_classes=vocab_size)\n",
    "    seq_length = X.shape[1]+1\n",
    "#     seq_length =len(X[0])\n",
    "    msg = 'seq_length={}'.format(seq_length)\n",
    "    logging.info(msg)\n",
    "    print(\"\\n\" + msg)\n",
    "\n",
    "\n",
    "    # ------------------------------ TRAIN MODEL -----------------------------------\n",
    "    model = build_LM_A(vocab_size, seq_length, summary=summary)\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    history = model.fit(X, y, batch_size=BATCH, epochs=EPOCHS, verbose=1) \n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_seq(model, tokenizer, seq_length, seed_text, n_words):\n",
    "    result = []\n",
    "    in_text = seed_text\n",
    "    # generate a fixed number of words\n",
    "    for _ in range(n_words):\n",
    "        # encode the text as integer\n",
    "        encoded = tokenizer.texts_to_sequences([in_text])[0]\n",
    "        # truncate sequences to a fixed length\n",
    "        encoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
    "        # predict probabilities for each word\n",
    "        yhat = model.predict_classes(encoded, verbose=0)\n",
    "        # map predicted word index to word\n",
    "        out_word = ''\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == yhat:\n",
    "                out_word = word\n",
    "                break\n",
    "        # append to input\n",
    "        in_text += ' ' + out_word\n",
    "        result.append(out_word)\n",
    "    return ' '.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "depression total data=932\n",
      "WARNING:tensorflow:From <ipython-input-9-b6438cbb9c09>:11: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "anxiety total data=998\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "BATCH = 128\n",
    "n_seq_words = 20\n",
    "exp_count = 2\n",
    "summary = True \n",
    "save = False\n",
    "load_bool = True\n",
    "truncation_length = 50\n",
    "\n",
    "labels = {'depression': 0, 'anxiety': 1}\n",
    "results = []\n",
    "\n",
    "for label_str, label_int in labels.items():\n",
    "    # ------------------------------ PREPARE MODEL -----------------------------------\n",
    "    data = model_data[model_data[\"is_anxiety\"] == label_int][data_column]\n",
    "    \n",
    "    msg = \"{} total data={}\".format(label_str, len(data))\n",
    "    logging.info(msg)\n",
    "    print(msg)\n",
    "    \n",
    "    model_path = '../models/{}.language_model.h5'.format(label_str)\n",
    "    tokenizer_path = '../models/{}.language_model.tokenizer.pkl'.format(label_str)\n",
    "    processed_data_path = '../data/{}.language_model.processed_data.txt'.format(label_str)\n",
    "\n",
    "    if save:\n",
    "        model, history = language_model(label_str, data, n_seq_words, model_path, tokenizer_path, processed_data_path, EPOCHS, BATCH, summary)\n",
    "        model.save(model_path)\n",
    "        dump(tokenizer, open(tokenizer_path, 'wb'))\n",
    "    \n",
    "    if load_bool:\n",
    "        model = load_model(model_path)\n",
    "        tokenizer = load(open(tokenizer_path, 'rb'))\n",
    "\n",
    "\n",
    "    # ------------------------------ GENERATE EXAMPLE -----------------------------------\n",
    "    logging.info(\"Generating examples-> label={}, n_seq_words={}\".format(label_str, n_seq_words))\n",
    "\n",
    "    for i in range(exp_count):\n",
    "        seed_text = data[randint(data.index[0], data.index[-1]+1)]\n",
    "        while seed_text == \"emptypost\":\n",
    "            seed_text = data[randint(data.index[0], data.index[-1]+1)]\n",
    "#         print(\"seed_text\\n\", seed_text + '\\n')\n",
    "        seed_text = seed_text[:truncation_length]\n",
    "        \n",
    "        generated = generate_seq(model, tokenizer, n_seq_words, seed_text, n_seq_words)\n",
    "#         print(\"generated\", generated)\n",
    "        \n",
    "        model_results = {}\n",
    "        model_results[\"seed_text\"] = seed_text\n",
    "        model_results[\"generated\"] = generated\n",
    "        model_results[\"is_anxiety\"] = label_int\n",
    "        model_results[\"n_seq_words\"] = n_seq_words\n",
    "        results.append(model_results) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               seed_text  \\\n",
       "0                                                                                                                                                                                                                                 husband understand get bed get mad point lay morning complains getting actually took sheet morning trying wake ended cry annoyed left cry shower make feel worse thing like happen pretty much everyone except son afraid ending hurt depression tired physically mentally know also autistic like encouragement get opposite discouragement seems great either love indifference nobody capable seems also using throwaway main pretty upbeat wanna ruin edit tired think said already wanna go hang kid stop cry bed   \n",
       "1                                                                                                                                                                                                                                                                                                                                        brain conjures fictional character seen movie series read book instead talking real people talk constantly started wa young people listen hurt would imagine character like hp mickey mouse comforting listening 20 realized healthy tried everything always always conversation mind keep going idea stop becomes especially loud trying sleep trying focus something anyone doe thing please help figure stop   \n",
       "2                                                                                                                                                                      still kind new want disgusting yk already picked safe drink unsweetened iced tea need actual food restaurant would picked one follows covid rule way make u feel safe basically menu salad sushi burger sandwich sushi salad taco sandwich hard eat bc look unattractive lmao make self conscious salad lettuce get teeth something background last date got pizza hate half slice dinner would get salad avocado like telling waitress waiter thing bc awkward might forget avocado food might taco bc build skip tortilla eat meat idk pretty dang close cancelling whole thing   \n",
       "3  past 3 4 day experiencing increased anxiety irritability also trouble sleeping even taking sleep aid today anxiety skyrocketed apparent reason quick anger irritable also started neck upper back jaw pain feel tense uncomfortable neck tension worst easy get hot headache feel heart palpitation startle easily want note adderall 10mg bid never experience physical symptom stimulant unless take meal actually improves irritability dose month never issue wondering though maybe symptom see side effect showing reason maybe experiencing anxiety attack stressed lately due career extremely high stress working hospital really able relax come home due child home loud hyperverbal worst ever felt never experienced severe anxiety ever   \n",
       "\n",
       "                                                                                                                          generated  \\\n",
       "0   suffer happened something husband find fix told wa loss single time earth want around one memory working scared anxious distant   \n",
       "1  journaling playing depressant hardest hand made egg nowadays ha cancer even focus even smug symptom also police full paid future   \n",
       "2          even worse gosh moreover live away home entire yet could went away therapist talk goddamnit problem anxiety feel like wa   \n",
       "3      going stuff work space anxiety understand problem people tired please post know god want realise toxic heat huge walk mental   \n",
       "\n",
       "   is_anxiety  n_seq_words  \n",
       "0           0           20  \n",
       "1           0           20  \n",
       "2           1           20  \n",
       "3           1           20  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>seed_text</th>\n      <th>generated</th>\n      <th>is_anxiety</th>\n      <th>n_seq_words</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>husband understand get bed get mad point lay morning complains getting actually took sheet morning trying wake ended cry annoyed left cry shower make feel worse thing like happen pretty much everyone except son afraid ending hurt depression tired physically mentally know also autistic like encouragement get opposite discouragement seems great either love indifference nobody capable seems also using throwaway main pretty upbeat wanna ruin edit tired think said already wanna go hang kid stop cry bed</td>\n      <td>suffer happened something husband find fix told wa loss single time earth want around one memory working scared anxious distant</td>\n      <td>0</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>brain conjures fictional character seen movie series read book instead talking real people talk constantly started wa young people listen hurt would imagine character like hp mickey mouse comforting listening 20 realized healthy tried everything always always conversation mind keep going idea stop becomes especially loud trying sleep trying focus something anyone doe thing please help figure stop</td>\n      <td>journaling playing depressant hardest hand made egg nowadays ha cancer even focus even smug symptom also police full paid future</td>\n      <td>0</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>still kind new want disgusting yk already picked safe drink unsweetened iced tea need actual food restaurant would picked one follows covid rule way make u feel safe basically menu salad sushi burger sandwich sushi salad taco sandwich hard eat bc look unattractive lmao make self conscious salad lettuce get teeth something background last date got pizza hate half slice dinner would get salad avocado like telling waitress waiter thing bc awkward might forget avocado food might taco bc build skip tortilla eat meat idk pretty dang close cancelling whole thing</td>\n      <td>even worse gosh moreover live away home entire yet could went away therapist talk goddamnit problem anxiety feel like wa</td>\n      <td>1</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>past 3 4 day experiencing increased anxiety irritability also trouble sleeping even taking sleep aid today anxiety skyrocketed apparent reason quick anger irritable also started neck upper back jaw pain feel tense uncomfortable neck tension worst easy get hot headache feel heart palpitation startle easily want note adderall 10mg bid never experience physical symptom stimulant unless take meal actually improves irritability dose month never issue wondering though maybe symptom see side effect showing reason maybe experiencing anxiety attack stressed lately due career extremely high stress working hospital really able relax come home due child home loud hyperverbal worst ever felt never experienced severe anxiety ever</td>\n      <td>going stuff work space anxiety understand problem people tired please post know god want realise toxic heat huge walk mental</td>\n      <td>1</td>\n      <td>20</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "# pd.reset_option(\"max_colwidth\")\n",
    "pd.set_option(\"display.max_colwidth\", 1000)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "results = pd.DataFrame(results)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfi.export(results, '../reports/images/normal-lm_examples.png', max_cols=50, max_rows=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "964d23c0451dcf6eb9653ab29bf1b69d4b9cf2f8bbce59b0642e3dd73cc18be8"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.2 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}